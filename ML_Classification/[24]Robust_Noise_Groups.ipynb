{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Test - Noised Values - Features Groups\n",
    "for each features group in the data we will permute the values by setting randomly noise around the original value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set constants\n",
    "target_label = 'tuple'\n",
    "learning_model = 'et' # ['rf','et','lightgbm','xgboost']\n",
    "num_features = ['min_packet_size', 'min_fpkt', 'min_bpkt']\n",
    "file_name = \"new_all_features_\"\n",
    "path = \"../Datasets/\" + target_label + \"_dataset/\"\n",
    "maps_array = [{},{},{},{}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for making model-prediction over the data set and measure the run time \n",
    "def timed_prediction(in_data,in_model):\n",
    "    t = time.process_time()\n",
    "    predicted = predict_model(in_model, data=in_data)\n",
    "    elapsed_time = time.process_time() - t\n",
    "    print(\"prediction took: \" + str(elapsed_time))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare answers and labeled test\n",
    "def compare_prediction_with_answers(in_predicted, in_answers):\n",
    "    count=0\n",
    "    index = in_predicted.index\n",
    "    number_of_rows = len(index)\n",
    "    errors_arr = []\n",
    "    for i in range(0,number_of_rows):\n",
    "        if str(int(in_answers.iloc[i])) != str(int(in_predicted.iloc[i]['Label'])):\n",
    "            count=count+1\n",
    "            cur_error = str(in_answers[i]) + \"!=\" + str(in_predicted.iloc[i]['Label'])\n",
    "            errors_arr.append(cur_error)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_data(in_data, in_column_indx,noise):\n",
    "    cur_col=in_data[in_column_indx]\n",
    "    col_len = len(cur_col)\n",
    "    max_value = cur_col.max()\n",
    "    value = cur_col[0]\n",
    "    min_value = cur_col.min()\n",
    "    buffer = 0\n",
    "    for i in range(0,col_len):\n",
    "        cur_val = cur_col[i]\n",
    "        buffer = cur_val*noise\n",
    "        coeff = np.random.randint(0,1)\n",
    "        if coeff == 0: coeff=-1\n",
    "        cur_col[i] = cur_val + (coeff * buffer)\n",
    "    in_data[in_column_indx] = cur_col\n",
    "    return in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up features groups\n",
    "SSL_features = ['fSSL_session_id_len', 'fSSL_num_extensions', 'fcipher_suites', 'ssl_v', ]\n",
    "size_features = ['size_histogram_1','size_histogram_2','size_histogram_3',\n",
    "                 'size_histogram_4','size_histogram_5','size_histogram_6',\n",
    "                 'size_histogram_7','size_histogram_8','size_histogram_9', 'size_histogram_10',\n",
    "                'fpackets', 'bpackets', 'fbytes', 'bbytes','min_packet_size',\n",
    "                 'max_packet_size', 'mean_packet_size','sizevar']\n",
    "peak_features = ['fpeak_features_1','fpeak_features_2','fpeak_features_3',\n",
    "                 'fpeak_features_4','fpeak_features_5','fpeak_features_6',\n",
    "                 'fpeak_features_7','fpeak_features_8','fpeak_features_9',\n",
    "                 'bpeak_features_1','bpeak_features_2','bpeak_features_3',\n",
    "                 'bpeak_features_4','bpeak_features_5','bpeak_features_6',\n",
    "                 'bpeak_features_7','bpeak_features_8','bpeak_features_9']\n",
    "TCP_features = ['SYN_tcp_scale', 'SYN_tcp_winsize']\n",
    "common_features = ['packet_count','num_keep_alive', 'mean_fttl',\n",
    "                   'max_fpkt','max_bpkt','std_fpkt','std_bpkt','mean_fpkt','mean_bpkt']\n",
    "stat_features = ['min_packet_size', 'max_packet_size', 'mean_packet_size',\n",
    "                 'sizevar', 'std_fiat','max_fiat','max_biat','std_biat','mean_fiat','mean_biat',\n",
    "                'min_fpkt','min_bpkt','max_fpkt','max_bpkt','std_fpkt','std_bpkt','mean_fpkt','mean_bpkt']\n",
    "time_features = ['std_fiat','max_fiat','max_biat','std_biat','mean_fiat','mean_biat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Setup Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col0,#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col1,#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col2,#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col3,#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col4,#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col5,#T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col6{\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_9e57af18_29fa_11eb_83a4_00d8610889ae\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy</th>        <th class=\"col_heading level0 col1\" >AUC</th>        <th class=\"col_heading level0 col2\" >Recall</th>        <th class=\"col_heading level0 col3\" >Prec.</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >Kappa</th>        <th class=\"col_heading level0 col6\" >MCC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col0\" class=\"data row0 col0\" >0.9664</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col1\" class=\"data row0 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col2\" class=\"data row0 col2\" >0.8571</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col3\" class=\"data row0 col3\" >0.9646</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col4\" class=\"data row0 col4\" >0.9649</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col5\" class=\"data row0 col5\" >0.9606</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow0_col6\" class=\"data row0 col6\" >0.9607</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col0\" class=\"data row1 col0\" >0.9763</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col1\" class=\"data row1 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col2\" class=\"data row1 col2\" >0.9277</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col3\" class=\"data row1 col3\" >0.9776</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col4\" class=\"data row1 col4\" >0.9750</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col5\" class=\"data row1 col5\" >0.9722</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow1_col6\" class=\"data row1 col6\" >0.9723</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col0\" class=\"data row2 col0\" >0.9782</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col1\" class=\"data row2 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col2\" class=\"data row2 col2\" >0.9264</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col3\" class=\"data row2 col3\" >0.9783</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col4\" class=\"data row2 col4\" >0.9772</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col5\" class=\"data row2 col5\" >0.9745</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow2_col6\" class=\"data row2 col6\" >0.9746</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col0\" class=\"data row3 col0\" >0.9822</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col1\" class=\"data row3 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col2\" class=\"data row3 col2\" >0.9185</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col3\" class=\"data row3 col3\" >0.9824</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col4\" class=\"data row3 col4\" >0.9817</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col5\" class=\"data row3 col5\" >0.9792</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow3_col6\" class=\"data row3 col6\" >0.9792</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col0\" class=\"data row4 col0\" >0.9763</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col1\" class=\"data row4 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col2\" class=\"data row4 col2\" >0.9212</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col3\" class=\"data row4 col3\" >0.9778</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col4\" class=\"data row4 col4\" >0.9765</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col5\" class=\"data row4 col5\" >0.9722</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow4_col6\" class=\"data row4 col6\" >0.9723</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col0\" class=\"data row5 col0\" >0.9664</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col1\" class=\"data row5 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col2\" class=\"data row5 col2\" >0.8837</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col3\" class=\"data row5 col3\" >0.9686</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col4\" class=\"data row5 col4\" >0.9660</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col5\" class=\"data row5 col5\" >0.9607</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow5_col6\" class=\"data row5 col6\" >0.9607</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col0\" class=\"data row6 col0\" >0.9773</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col1\" class=\"data row6 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col2\" class=\"data row6 col2\" >0.8872</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col3\" class=\"data row6 col3\" >0.9769</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col4\" class=\"data row6 col4\" >0.9763</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col5\" class=\"data row6 col5\" >0.9734</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow6_col6\" class=\"data row6 col6\" >0.9734</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col0\" class=\"data row7 col0\" >0.9733</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col1\" class=\"data row7 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col2\" class=\"data row7 col2\" >0.8802</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col3\" class=\"data row7 col3\" >0.9724</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col4\" class=\"data row7 col4\" >0.9715</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col5\" class=\"data row7 col5\" >0.9687</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow7_col6\" class=\"data row7 col6\" >0.9688</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col0\" class=\"data row8 col0\" >0.9782</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col1\" class=\"data row8 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col2\" class=\"data row8 col2\" >0.8743</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col3\" class=\"data row8 col3\" >0.9767</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col4\" class=\"data row8 col4\" >0.9764</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col5\" class=\"data row8 col5\" >0.9745</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow8_col6\" class=\"data row8 col6\" >0.9746</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col0\" class=\"data row9 col0\" >0.9832</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col1\" class=\"data row9 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col2\" class=\"data row9 col2\" >0.8695</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col3\" class=\"data row9 col3\" >0.9815</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col4\" class=\"data row9 col4\" >0.9821</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col5\" class=\"data row9 col5\" >0.9803</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow9_col6\" class=\"data row9 col6\" >0.9803</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col0\" class=\"data row10 col0\" >0.9758</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col1\" class=\"data row10 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col2\" class=\"data row10 col2\" >0.8946</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col3\" class=\"data row10 col3\" >0.9757</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col4\" class=\"data row10 col4\" >0.9748</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col5\" class=\"data row10 col5\" >0.9716</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow10_col6\" class=\"data row10 col6\" >0.9717</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aelevel0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col0\" class=\"data row11 col0\" >0.0054</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col1\" class=\"data row11 col1\" >0.0000</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col2\" class=\"data row11 col2\" >0.0249</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col3\" class=\"data row11 col3\" >0.0053</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col4\" class=\"data row11 col4\" >0.0055</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col5\" class=\"data row11 col5\" >0.0063</td>\n",
       "                        <td id=\"T_9e57af18_29fa_11eb_83a4_00d8610889aerow11_col6\" class=\"data row11 col6\" >0.0063</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d5f9666160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(path+file_name+target_label+'_train.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "\n",
    "setup(data=data,\n",
    "      target=target_label,\n",
    "      numeric_features=num_features,\n",
    "      silent=True)\n",
    "\n",
    "model=create_model(learning_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicte and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = unseen_data[target_label]\n",
    "unseen_data = unseen_data.drop(columns=[target_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict_model(model, data=unseen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction_with_answers(predicted,answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each group we will Read Test Data again, Change values, Predicte, Check and Saves result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSL Features Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current columns are : ['fSSL_session_id_len', 'fSSL_num_extensions', 'fcipher_suites', 'ssl_v']\n"
     ]
    }
   ],
   "source": [
    "current_group='SSL_Features'\n",
    "noise=0.05\n",
    "features_group = SSL_features\n",
    "print ('current columns are : ' + str(features_group))\n",
    "for index in range (0,4):\n",
    "    \n",
    "    unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "    \n",
    "    for i in features_group:\n",
    "        unseen_data = get_rand_data(unseen_data,i,noise)\n",
    "    answers = unseen_data[target_label]\n",
    "    unseen_data = unseen_data.drop(columns=[target_label])\n",
    "    predicted = predict_model(model, data=unseen_data)\n",
    "    result = compare_prediction_with_answers(predicted,answers)\n",
    "    maps_array[index][current_group] = result\n",
    "    \n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Features Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current columns are : ['size_histogram_1', 'size_histogram_2', 'size_histogram_3', 'size_histogram_4', 'size_histogram_5', 'size_histogram_6', 'size_histogram_7', 'size_histogram_8', 'size_histogram_9', 'size_histogram_10', 'fpackets', 'bpackets', 'fbytes', 'bbytes', 'min_packet_size', 'max_packet_size', 'mean_packet_size', 'sizevar']\n"
     ]
    }
   ],
   "source": [
    "current_group='Size_features'\n",
    "noise=0.05\n",
    "features_group = size_features\n",
    "print ('current columns are : ' + str(features_group))\n",
    "for index in range (0,4):\n",
    "    \n",
    "    unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "    \n",
    "    for i in features_group:\n",
    "        unseen_data = get_rand_data(unseen_data,i,noise)\n",
    "    answers = unseen_data[target_label]\n",
    "    unseen_data = unseen_data.drop(columns=[target_label])\n",
    "    predicted = predict_model(model, data=unseen_data)\n",
    "    result = compare_prediction_with_answers(predicted,answers)\n",
    "    maps_array[index][current_group] = result\n",
    "    \n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMMON Features Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current columns are : ['packet_count', 'num_keep_alive', 'mean_fttl', 'max_fpkt', 'max_bpkt', 'std_fpkt', 'std_bpkt', 'mean_fpkt', 'mean_bpkt']\n"
     ]
    }
   ],
   "source": [
    "current_group='Common_features'\n",
    "noise=0.05\n",
    "features_group = common_features\n",
    "print ('current columns are : ' + str(features_group))\n",
    "for index in range (0,4):\n",
    "    \n",
    "    unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "    \n",
    "    for i in features_group:\n",
    "        unseen_data = get_rand_data(unseen_data,i,noise)\n",
    "    answers = unseen_data[target_label]\n",
    "    unseen_data = unseen_data.drop(columns=[target_label])\n",
    "    predicted = predict_model(model, data=unseen_data)\n",
    "    result = compare_prediction_with_answers(predicted,answers)\n",
    "    maps_array[index][current_group] = result\n",
    "    \n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCP Features Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current columns are : ['SYN_tcp_scale', 'SYN_tcp_winsize']\n"
     ]
    }
   ],
   "source": [
    "current_group='TCP_features'\n",
    "noise=0.05\n",
    "features_group = TCP_features\n",
    "print ('current columns are : ' + str(features_group))\n",
    "for index in range (0,4):\n",
    "    \n",
    "    unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "    \n",
    "    for i in features_group:\n",
    "        unseen_data = get_rand_data(unseen_data,i,noise)\n",
    "    answers = unseen_data[target_label]\n",
    "    unseen_data = unseen_data.drop(columns=[target_label])\n",
    "    predicted = predict_model(model, data=unseen_data)\n",
    "    result = compare_prediction_with_answers(predicted,answers)\n",
    "    maps_array[index][current_group] = result\n",
    "    \n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT Features Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current columns are : ['min_packet_size', 'max_packet_size', 'mean_packet_size', 'sizevar', 'std_fiat', 'max_fiat', 'max_biat', 'std_biat', 'mean_fiat', 'mean_biat', 'min_fpkt', 'min_bpkt', 'max_fpkt', 'max_bpkt', 'std_fpkt', 'std_bpkt', 'mean_fpkt', 'mean_bpkt']\n"
     ]
    }
   ],
   "source": [
    "current_group='Statistics_features'\n",
    "noise=0.05\n",
    "features_group = stat_features\n",
    "print ('current columns are : ' + str(features_group))\n",
    "for index in range (0,4):\n",
    "    \n",
    "    unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "    \n",
    "    for i in features_group:\n",
    "        unseen_data = get_rand_data(unseen_data,i,noise)\n",
    "    answers = unseen_data[target_label]\n",
    "    unseen_data = unseen_data.drop(columns=[target_label])\n",
    "    predicted = predict_model(model, data=unseen_data)\n",
    "    result = compare_prediction_with_answers(predicted,answers)\n",
    "    maps_array[index][current_group] = result\n",
    "    \n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Features Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current columns are : ['std_fiat', 'max_fiat', 'max_biat', 'std_biat', 'mean_fiat', 'mean_biat']\n"
     ]
    }
   ],
   "source": [
    "current_group='Time_features'\n",
    "noise=0.05\n",
    "features_group = time_features\n",
    "print ('current columns are : ' + str(features_group))\n",
    "for index in range (0,4):\n",
    "    \n",
    "    unseen_data = pd.read_csv(path+file_name+target_label+'_test.csv',\n",
    "                      sep='\\t',\n",
    "                      skiprows=[1])\n",
    "    \n",
    "    for i in features_group:\n",
    "        unseen_data = get_rand_data(unseen_data,i,noise)\n",
    "    answers = unseen_data[target_label]\n",
    "    unseen_data = unseen_data.drop(columns=[target_label])\n",
    "    predicted = predict_model(model, data=unseen_data)\n",
    "    result = compare_prediction_with_answers(predicted,answers)\n",
    "    maps_array[index][current_group] = result\n",
    "    \n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of errors for group feature with 0.05 randomly noise around the original value.\n",
      "[('TCP_features', 2209), ('SSL_Features', 2059), ('Statistics_features', 188), ('Size_features', 164), ('Common_features', 146), ('Time_features', 142)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "number of errors for group feature with 0.1 randomly noise around the original value.\n",
      "[('TCP_features', 2209), ('SSL_Features', 2082), ('Statistics_features', 408), ('Size_features', 183), ('Common_features', 155), ('Time_features', 144)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "number of errors for group feature with 0.15000000000000002 randomly noise around the original value.\n",
      "[('TCP_features', 2337), ('SSL_Features', 2100), ('Statistics_features', 747), ('Size_features', 243), ('Common_features', 159), ('Time_features', 150)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "number of errors for group feature with 0.2 randomly noise around the original value.\n",
      "[('TCP_features', 2337), ('SSL_Features', 2117), ('Statistics_features', 1119), ('Size_features', 320), ('Common_features', 171), ('Time_features', 149)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise=0.05\n",
    "sorted_results_array = []\n",
    "for index in range (0,4):\n",
    "    print(\"\\n\")\n",
    "    print(\"number of errors for group feature with \" + str(noise) + \" randomly noise around the original value.\")\n",
    "    sorted_results_array.append([(k, v) for k, v in sorted(maps_array[index].items(), key=lambda x: x[1], reverse=True)])\n",
    "    print(sorted_results_array[index])\n",
    "    print(\"\\n\")\n",
    "    noise=noise+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so our prediction is very sensitive to noise with TCP_features and SSL_Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaed19ee87b6844ca4b2207fe8765813ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
